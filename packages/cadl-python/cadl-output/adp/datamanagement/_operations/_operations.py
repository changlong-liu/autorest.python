# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import json
import sys
from typing import Any, Callable, Dict, IO, Iterable, Optional, TypeVar, Union, cast, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpResponse
from azure.core.polling import LROPoller, NoPolling, PollingMethod
from azure.core.polling.base_polling import LROBasePolling
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .. import models as _models
from .._model_base import AzureJSONEncoder, _deserialize
from .._serialization import Serializer
from .._vendor import DataManagementClientMixinABC, _format_url_section

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_data_management_get_status_request(operation_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/operations/{operationId}"
    path_format_arguments = {
        "operationId": _SERIALIZER.url("operation_id", operation_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_or_replace_request(
    discovery_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(discovery_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_complete_request(
    discovery_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}:complete"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_cancel_request(
    discovery_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}:cancel"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_generate_request(
    discovery_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}/specialFilesUploadInfo:generate"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_writable_uris_request(
    discovery_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}/specialFilesUploadInfo:listWritableUris"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(discovery_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/discoveries/{discoveryId}/uploads"
    path_format_arguments = {
        "discoveryId": _SERIALIZER.url("discovery_id", discovery_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_or_replace_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_complete_request(
    upload_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}:complete"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_cancel_request(
    upload_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}:cancel"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/specialFilesUploadInfo"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_generate_request(
    upload_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/specialFilesUploadInfo:generate"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_writable_uris_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/specialFilesUploadInfo:listWritableUris"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_generate_request(
    upload_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/dataFilesUploadInfo:generate"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_writable_uris_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/dataFilesUploadInfo:listWritableUris"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(upload_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/uploads/{uploadId}/measurements"
    path_format_arguments = {
        "uploadId": _SERIALIZER.url("upload_id", upload_id, "str", max_length=36, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(name: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/classificationSchemas/{name}"
    path_format_arguments = {
        "name": _SERIALIZER.url("name", name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/classificationSchemas"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_delete_request(
    name: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/classificationSchemas/{name}"
    path_format_arguments = {
        "name": _SERIALIZER.url("name", name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(*, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/classificationSchemas"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_delete_request(
    measurement_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(*, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_query_measurements_with_metadata_request(*, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements:queryMeasurementsWithMetadata"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_find_by_ids_request(*, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements:findByIds"

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/metadata"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/processingResults"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(measurement_id: str, id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/stateMachines/{id}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "id": _SERIALIZER.url("id", id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/stateMachines"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_act_request(
    measurement_id: str, id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/stateMachines/{id}:act"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "id": _SERIALIZER.url("id", id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_complete_request(
    measurement_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/metadataFileInfo:complete"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_writable_uri_request(
    measurement_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/metadataFileInfo:getWritableUri"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/metadataSchemaFileInfo"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(
    measurement_id: str, schema_name: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/classifications/{schemaName}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "schemaName": _SERIALIZER.url("schema_name", schema_name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    measurement_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/classifications"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_delete_request(
    measurement_id: str, schema_name: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/classifications/{schemaName}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "schemaName": _SERIALIZER.url("schema_name", schema_name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/classifications"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    measurement_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_clear_content_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}:clearContent"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(
    measurement_id: str, *, api_version: str, filter: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if filter is not None:
        _params["filter"] = _SERIALIZER.query("filter", filter, "str")
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_stage_files_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}:stageFiles"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_complete_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}:complete"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_fail_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}:fail"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_find_by_tags_request(measurement_id: str, *, api_version: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams:findByTags"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_find_by_lineage_request(
    measurement_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams:findByLineage"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_lineage_graphs_by_lineage_request(
    measurement_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams:getLineageGraphsByLineage"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/storage"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_writable_uris_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/storage:getWritableUris"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/tags"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/tags"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/files"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_generate_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/files:generate"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_writable_uri_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/logs:getWritableUri"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_get_request(
    measurement_id: str, data_stream_id: str, schema_name: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/classifications/{schemaName}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
        "schemaName": _SERIALIZER.url("schema_name", schema_name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_create_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, operation_id: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/classifications"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_delete_request(
    measurement_id: str,
    data_stream_id: str,
    schema_name: str,
    *,
    api_version: str,
    operation_id: Optional[str] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/classifications/{schemaName}"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
        "schemaName": _SERIALIZER.url("schema_name", schema_name, "str", max_length=256, min_length=1),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    if operation_id is not None:
        _headers["operation-id"] = _SERIALIZER.header("operation_id", operation_id, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)


def build_data_management_list_request(
    measurement_id: str, data_stream_id: str, *, api_version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/measurements/{measurementId}/dataStreams/{dataStreamId}/classifications"
    path_format_arguments = {
        "measurementId": _SERIALIZER.url("measurement_id", measurement_id, "str"),
        "dataStreamId": _SERIALIZER.url("data_stream_id", data_stream_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    _params["api-version"] = _SERIALIZER.query("api_version", api_version, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


class DataManagementClientOperationsMixin(DataManagementClientMixinABC):  # pylint: disable=too-many-public-methods
    @distributed_trace
    def get_status(self, operation_id: str, **kwargs: Any) -> _models.LongRunningOperationWithResponseHeaders:
        """Get the details of an LRO.

        :param operation_id: The unique ID of the operation. Required.
        :type operation_id: str
        :return: LongRunningOperationWithResponseHeaders. The LongRunningOperationWithResponseHeaders
         is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.LongRunningOperationWithResponseHeaders
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.LongRunningOperationWithResponseHeaders] = kwargs.pop("cls", None)

        request = build_data_management_get_status_request(
            operation_id=operation_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))

        deserialized = _deserialize(_models.LongRunningOperationWithResponseHeaders, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def create_or_replace(
        self,
        discovery_id: str,
        body: Union[Optional[_models.Discovery], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Discovery:
        """Creates a new ingestion discovery instance.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :param body: Parameter of type 'DiscoveryCreationParameters' in the body. Default value is
         None.
        :type body: ~adp.datamanagement.models.Discovery or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Discovery. The Discovery is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Discovery
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_or_replace(
        self, discovery_id: str, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.Discovery:
        """Creates a new ingestion discovery instance.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :param body: Parameter of type 'DiscoveryCreationParameters' in the body. Default value is
         None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Discovery. The Discovery is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Discovery
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create_or_replace(
        self, discovery_id: str, body: Union[Optional[Union[_models.Discovery, JSON, IO]]] = None, **kwargs: Any
    ) -> _models.Discovery:
        """Creates a new ingestion discovery instance.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :param body: Parameter of type 'DiscoveryCreationParameters' in the body. Is either a model
         type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.Discovery or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: Discovery. The Discovery is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Discovery
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Discovery] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_or_replace_request(
            discovery_id=discovery_id,
            api_version=self._config.api_version,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            deserialized = _deserialize(_models.Discovery, response.json())

        if response.status_code == 201:
            deserialized = _deserialize(_models.Discovery, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, discovery_id: str, **kwargs: Any) -> _models.Discovery:
        """Get discovery by ID.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :return: Discovery. The Discovery is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Discovery
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Discovery] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            discovery_id=discovery_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.Discovery, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _complete_initial(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.Discovery, _models.DiscoveryLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.Discovery, _models.DiscoveryLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_complete_request(
            discovery_id=discovery_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.Discovery, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DiscoveryLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_complete(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.Discovery], LROPoller[_models.DiscoveryLroResponse]]:
        """Initiates the process of completing the discovery and creating the upload file grouping
        manifest files.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns Discovery or An instance of LROPoller that
         returns DiscoveryLroResponse. The Discovery is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.Discovery] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DiscoveryLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Discovery] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._complete_initial(
                discovery_id=discovery_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.Discovery, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _cancel_initial(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.Discovery, _models.DiscoveryLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.Discovery, _models.DiscoveryLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_cancel_request(
            discovery_id=discovery_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.Discovery, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DiscoveryLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_cancel(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.Discovery], LROPoller[_models.DiscoveryLroResponse]]:
        """Initiates the process of cancelling the discovery.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns Discovery or An instance of LROPoller that
         returns DiscoveryLroResponse. The Discovery is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.Discovery] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DiscoveryLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Discovery] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._cancel_initial(
                discovery_id=discovery_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.Discovery, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _generate_initial(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.DiscoverySpecialFile, _models.DiscoveryLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.DiscoverySpecialFile, _models.DiscoveryLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_generate_request(
            discovery_id=discovery_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DiscoverySpecialFile, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DiscoveryLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_generate(
        self, discovery_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.DiscoverySpecialFile], LROPoller[_models.DiscoveryLroResponse]]:
        """Initiates the process of generating SAS signed URIs for uploading special files for the
        discovery.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DiscoverySpecialFile or An instance of LROPoller
         that returns DiscoveryLroResponse. The DiscoverySpecialFile is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DiscoverySpecialFile] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DiscoveryLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DiscoverySpecialFile] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._generate_initial(
                discovery_id=discovery_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DiscoverySpecialFile, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list_writable_uris(self, discovery_id: str, **kwargs: Any) -> Iterable["_models.DiscoverySpecialFile"]:
        """List special files details for the discovery resource.
        Returns SAS signed URI that allows uploading special files to Azure Storage.
        This URI expires in 24 hours.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :return: An iterator like instance of DiscoverySpecialFile. The DiscoverySpecialFile is
         compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DiscoverySpecialFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDiscoverySpecialFile] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_writable_uris_request(
                    discovery_id=discovery_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDiscoverySpecialFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def list(self, discovery_id: str, **kwargs: Any) -> Iterable["_models.DiscoveryUpload"]:
        """List upload detail for the discovery resource.

        :param discovery_id: The discovery identifier. Required.
        :type discovery_id: str
        :return: An iterator like instance of DiscoveryUpload. The DiscoveryUpload is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DiscoveryUpload]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDiscoveryUpload] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    discovery_id=discovery_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDiscoveryUpload, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def create_or_replace(
        self,
        upload_id: str,
        body: Union[Optional[_models.Upload], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Upload:
        """Creates a new ingestion upload instance.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :param body: Parameter of type 'UploadCreationParameters' in the body. Default value is None.
        :type body: ~adp.datamanagement.models.Upload or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Upload. The Upload is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Upload
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_or_replace(
        self, upload_id: str, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> _models.Upload:
        """Creates a new ingestion upload instance.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :param body: Parameter of type 'UploadCreationParameters' in the body. Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Upload. The Upload is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Upload
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create_or_replace(
        self, upload_id: str, body: Union[Optional[Union[_models.Upload, JSON, IO]]] = None, **kwargs: Any
    ) -> _models.Upload:
        """Creates a new ingestion upload instance.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :param body: Parameter of type 'UploadCreationParameters' in the body. Is either a model type
         or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.Upload or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: Upload. The Upload is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Upload
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Upload] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_or_replace_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            deserialized = _deserialize(_models.Upload, response.json())

        if response.status_code == 201:
            deserialized = _deserialize(_models.Upload, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, upload_id: str, **kwargs: Any) -> _models.Upload:
        """Get discovery by ID.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :return: Upload. The Upload is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Upload
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Upload] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.Upload, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _complete_initial(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.Upload, _models.UploadLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.Upload, _models.UploadLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_complete_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.Upload, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.UploadLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_complete(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.Upload], LROPoller[_models.UploadLroResponse]]:
        """Initiates the process of completing the upload and creating the measurements.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns Upload or An instance of LROPoller that returns
         UploadLroResponse. The Upload is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.Upload] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Upload] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._complete_initial(
                upload_id=upload_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.Upload, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _cancel_initial(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.Upload, _models.UploadLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.Upload, _models.UploadLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_cancel_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.Upload, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.UploadLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_cancel(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.Upload], LROPoller[_models.UploadLroResponse]]:
        """Initiates the process of cancelling the upload.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns Upload or An instance of LROPoller that returns
         UploadLroResponse. The Upload is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.Upload] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Upload] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._cancel_initial(
                upload_id=upload_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.Upload, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(self, upload_id: str, **kwargs: Any) -> Iterable["_models.UploadSpecialFile"]:
        """Returns SAS signed URIs for reading special files from Azure Storage.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :return: An iterator like instance of UploadSpecialFile. The UploadSpecialFile is compatible
         with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.UploadSpecialFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedUploadSpecialFile] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    upload_id=upload_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedUploadSpecialFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _generate_initial(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.UploadSpecialFile, _models.UploadLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.UploadSpecialFile, _models.UploadLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_generate_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.UploadSpecialFile, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.UploadLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_generate(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.UploadSpecialFile], LROPoller[_models.UploadLroResponse]]:
        """Initiates the process of generating SAS signed URIs for uploading special files for the upload.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns UploadSpecialFile or An instance of LROPoller
         that returns UploadLroResponse. The UploadSpecialFile is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadSpecialFile] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.UploadSpecialFile] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._generate_initial(
                upload_id=upload_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.UploadSpecialFile, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list_writable_uris(self, upload_id: str, **kwargs: Any) -> Iterable["_models.UploadSpecialFile"]:
        """List special files details for the upload resource.
        Returns SAS signed URI that allows uploading special files to Azure Storage.
        This URI expires in 24 hours.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :return: An iterator like instance of UploadSpecialFile. The UploadSpecialFile is compatible
         with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.UploadSpecialFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedUploadSpecialFile] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_writable_uris_request(
                    upload_id=upload_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedUploadSpecialFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _generate_initial(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.UploadDataFile, _models.UploadLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.UploadDataFile, _models.UploadLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_generate_request(
            upload_id=upload_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.UploadDataFile, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.UploadLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_generate(
        self, upload_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.UploadDataFile], LROPoller[_models.UploadLroResponse]]:
        """Initiates the process of allocating the data files.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns UploadDataFile or An instance of LROPoller that
         returns UploadLroResponse. The UploadDataFile is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadDataFile] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.UploadLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.UploadDataFile] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._generate_initial(
                upload_id=upload_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.UploadDataFile, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list_writable_uris(self, upload_id: str, **kwargs: Any) -> Iterable["_models.UploadDataFile"]:
        """List special files details for the upload resource.
        Returns SAS signed URI that allows uploading data files to Azure Storage.
        This URI expires in 24 hours.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :return: An iterator like instance of UploadDataFile. The UploadDataFile is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.UploadDataFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedUploadDataFile] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_writable_uris_request(
                    upload_id=upload_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedUploadDataFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def list(self, upload_id: str, **kwargs: Any) -> Iterable["_models.UploadResultMeasurement"]:
        """List of the measurement identifiers that have been created by the upload.

        :param upload_id: The upload resource identifier. Required.
        :type upload_id: str
        :return: An iterator like instance of UploadResultMeasurement. The UploadResultMeasurement is
         compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.UploadResultMeasurement]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedUploadResultMeasurement] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    upload_id=upload_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedUploadResultMeasurement, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def get(self, name: str, **kwargs: Any) -> _models.ClassificationSchema:
        """Get classification schema by name.

        :param name: Classification schema identifier. Required.
        :type name: str
        :return: ClassificationSchema. The ClassificationSchema is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.ClassificationSchema
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.ClassificationSchema] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            name=name,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.ClassificationSchema, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _create_initial(
        self,
        body: Union[Optional[Union[_models.ClassificationSchema, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.ClassificationSchema, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.ClassificationSchema, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.ClassificationSchema, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_create(
        self,
        body: Union[Optional[_models.ClassificationSchema], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.ClassificationSchema], LROPoller[_models.DefaultLroResponse]]:
        """Creates new classification schema.

        :param body: Parameter of type 'ClassificationSchemaCreationParameters' in the body. Default
         value is None.
        :type body: ~adp.datamanagement.models.ClassificationSchema or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns ClassificationSchema or An instance of LROPoller
         that returns DefaultLroResponse. The ClassificationSchema is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.ClassificationSchema] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_create(
        self,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.ClassificationSchema], LROPoller[_models.DefaultLroResponse]]:
        """Creates new classification schema.

        :param body: Parameter of type 'ClassificationSchemaCreationParameters' in the body. Default
         value is None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns ClassificationSchema or An instance of LROPoller
         that returns DefaultLroResponse. The ClassificationSchema is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.ClassificationSchema] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_create(
        self,
        body: Union[Optional[Union[_models.ClassificationSchema, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.ClassificationSchema], LROPoller[_models.DefaultLroResponse]]:
        """Creates new classification schema.

        :param body: Parameter of type 'ClassificationSchemaCreationParameters' in the body. Is either
         a model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.ClassificationSchema or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns ClassificationSchema or An instance of LROPoller
         that returns DefaultLroResponse. The ClassificationSchema is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.ClassificationSchema] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.ClassificationSchema] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._create_initial(
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.ClassificationSchema, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _delete_initial(
        self, name: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Optional[_models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Optional[_models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_delete_request(
            name=name,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202, 204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        deserialized = None
        response_headers = {}
        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)

        return deserialized

    @distributed_trace
    def begin_delete(
        self, name: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> LROPoller[_models.DefaultLroResponse]:
        """Deletes the classification schema and all related classification assignments (instances).

        :param name: Classification schema identifier. Required.
        :type name: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DefaultLroResponse. The DefaultLroResponse is
         compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DefaultLroResponse] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._delete_initial(
                name=name, operation_id=operation_id, cls=lambda x, y, z: x, headers=_headers, params=_params, **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response_headers = {}
            response = pipeline_response.http_response
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())
            if cls:
                return cls(pipeline_response, deserialized, response_headers)
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(self, **kwargs: Any) -> Iterable["_models.ClassificationSchema"]:
        """List all classification schemas.

        :return: An iterator like instance of ClassificationSchema. The ClassificationSchema is
         compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.ClassificationSchema]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedClassificationSchema] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedClassificationSchema, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def get(self, measurement_id: str, **kwargs: Any) -> _models.Measurement:
        """Get measurement by ID.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: Measurement. The Measurement is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.Measurement
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Measurement] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.Measurement, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _delete_initial(
        self, measurement_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Optional[_models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Optional[_models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_delete_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202, 204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        deserialized = None
        response_headers = {}
        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)

        return deserialized

    @distributed_trace
    def begin_delete(
        self, measurement_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> LROPoller[_models.DefaultLroResponse]:
        """Deletes the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DefaultLroResponse. The DefaultLroResponse is
         compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DefaultLroResponse] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._delete_initial(
                measurement_id=measurement_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response_headers = {}
            response = pipeline_response.http_response
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())
            if cls:
                return cls(pipeline_response, deserialized, response_headers)
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(self, **kwargs: Any) -> Iterable["_models.Measurement"]:
        """Lists the measurements in a workspace.

        :return: An iterator like instance of Measurement. The Measurement is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.Measurement]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedMeasurement] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedMeasurement, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def query_measurements_with_metadata(self, **kwargs: Any) -> Iterable["_models.MeasurementWithMetadata"]:
        """Lists the measurements in a workspace with extended metadata.

        :return: An iterator like instance of MeasurementWithMetadata. The MeasurementWithMetadata is
         compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.MeasurementWithMetadata]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedMeasurementWithMetadata] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_query_measurements_with_metadata_request(
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedMeasurementWithMetadata, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def find_by_ids(
        self,
        body: Union[Optional[_models.MeasurementListRequestParameters], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Iterable["_models.Measurement"]:
        """Lists the measurements in a workspace that are in the given measurement IDs list.

        :param body: Parameter of type 'MeasurementListRequestParameters' in the body. Default value is
         None.
        :type body: ~adp.datamanagement.models.MeasurementListRequestParameters or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of Measurement. The Measurement is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.Measurement]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def find_by_ids(
        self, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> Iterable["_models.Measurement"]:
        """Lists the measurements in a workspace that are in the given measurement IDs list.

        :param body: Parameter of type 'MeasurementListRequestParameters' in the body. Default value is
         None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of Measurement. The Measurement is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.Measurement]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def find_by_ids(
        self, body: Union[Optional[Union[_models.MeasurementListRequestParameters, JSON, IO]]] = None, **kwargs: Any
    ) -> Iterable["_models.Measurement"]:
        """Lists the measurements in a workspace that are in the given measurement IDs list.

        :param body: Parameter of type 'MeasurementListRequestParameters' in the body. Is either a
         model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.MeasurementListRequestParameters or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: An iterator like instance of Measurement. The Measurement is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.Measurement]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models._models.PagedMeasurement] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_find_by_ids_request(
                    api_version=self._config.api_version,
                    content_type=content_type,
                    content=_content,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedMeasurement, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def get(self, measurement_id: str, **kwargs: Any) -> _models.MeasurementMetadataBase:
        """Returns the measurement metadata.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: MeasurementMetadataBase. The MeasurementMetadataBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.MeasurementMetadataBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.MeasurementMetadataBase] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.MeasurementMetadataBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, measurement_id: str, **kwargs: Any) -> _models.MeasurementProcessingResultsBase:
        """Returns the measurement processing result.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: MeasurementProcessingResultsBase. The MeasurementProcessingResultsBase is compatible
         with MutableMapping
        :rtype: ~adp.datamanagement.models.MeasurementProcessingResultsBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.MeasurementProcessingResultsBase] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.MeasurementProcessingResultsBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, measurement_id: str, id: str, **kwargs: Any) -> _models.StateMachine:
        """Returns the state machine instance for the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param id: The state machine identifier. Required.
        :type id: str
        :return: StateMachine. The StateMachine is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.StateMachine
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.StateMachine] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            id=id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.StateMachine, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list(self, measurement_id: str, **kwargs: Any) -> Iterable["_models.StateMachine"]:
        """List state machines instance for the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: An iterator like instance of StateMachine. The StateMachine is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.StateMachine]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedStateMachine] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedStateMachine, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _act_initial(
        self,
        measurement_id: str,
        id: str,
        body: Union[Optional[Union[_models.StateMachineAction, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.StateMachine, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.StateMachine, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_act_request(
            measurement_id=measurement_id,
            id=id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.StateMachine, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_act(
        self,
        measurement_id: str,
        id: str,
        body: Union[Optional[_models.StateMachineAction], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.StateMachine], LROPoller[_models.DefaultLroResponse]]:
        """Initiates process of applying an action on the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param id: The state machine identifier. Required.
        :type id: str
        :param body: Parameter of type 'StateMachineAction' in the body. Default value is None.
        :type body: ~adp.datamanagement.models.StateMachineAction or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns StateMachine or An instance of LROPoller that
         returns DefaultLroResponse. The StateMachine is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.StateMachine] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_act(
        self,
        measurement_id: str,
        id: str,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.StateMachine], LROPoller[_models.DefaultLroResponse]]:
        """Initiates process of applying an action on the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param id: The state machine identifier. Required.
        :type id: str
        :param body: Parameter of type 'StateMachineAction' in the body. Default value is None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns StateMachine or An instance of LROPoller that
         returns DefaultLroResponse. The StateMachine is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.StateMachine] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_act(
        self,
        measurement_id: str,
        id: str,
        body: Union[Optional[Union[_models.StateMachineAction, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.StateMachine], LROPoller[_models.DefaultLroResponse]]:
        """Initiates process of applying an action on the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param id: The state machine identifier. Required.
        :type id: str
        :param body: Parameter of type 'StateMachineAction' in the body. Is either a model type or a IO
         type. Default value is None.
        :type body: ~adp.datamanagement.models.StateMachineAction or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns StateMachine or An instance of LROPoller that
         returns DefaultLroResponse. The StateMachine is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.StateMachine] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.StateMachine] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._act_initial(
                measurement_id=measurement_id,
                id=id,
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.StateMachine, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _complete_initial(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.CompleteUploadMetadataFileRequest, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.MeasurementMetadataFileInfoBase, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.MeasurementMetadataFileInfoBase, _models.DefaultLroResponse]] = kwargs.pop(
            "cls", None
        )

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_complete_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        if response.status_code == 200:
            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))

            deserialized = _deserialize(_models.MeasurementMetadataFileInfoBase, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_complete(
        self,
        measurement_id: str,
        body: Union[Optional[_models.CompleteUploadMetadataFileRequest], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementMetadataFileInfoBase], LROPoller[_models.DefaultLroResponse]]:
        """Initiates a process that replaces the measurement's metadata file.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'CompleteUploadMetadataFileRequest' in the body. Default value
         is None.
        :type body: ~adp.datamanagement.models.CompleteUploadMetadataFileRequest or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementMetadataFileInfoBase or An instance
         of LROPoller that returns DefaultLroResponse. The MeasurementMetadataFileInfoBase is compatible
         with MutableMapping
        :rtype:
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementMetadataFileInfoBase] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_complete(
        self,
        measurement_id: str,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementMetadataFileInfoBase], LROPoller[_models.DefaultLroResponse]]:
        """Initiates a process that replaces the measurement's metadata file.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'CompleteUploadMetadataFileRequest' in the body. Default value
         is None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementMetadataFileInfoBase or An instance
         of LROPoller that returns DefaultLroResponse. The MeasurementMetadataFileInfoBase is compatible
         with MutableMapping
        :rtype:
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementMetadataFileInfoBase] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_complete(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.CompleteUploadMetadataFileRequest, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementMetadataFileInfoBase], LROPoller[_models.DefaultLroResponse]]:
        """Initiates a process that replaces the measurement's metadata file.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'CompleteUploadMetadataFileRequest' in the body. Is either a
         model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.CompleteUploadMetadataFileRequest or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementMetadataFileInfoBase or An instance
         of LROPoller that returns DefaultLroResponse. The MeasurementMetadataFileInfoBase is compatible
         with MutableMapping
        :rtype:
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementMetadataFileInfoBase] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.MeasurementMetadataFileInfoBase] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._complete_initial(
                measurement_id=measurement_id,
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response_headers = {}
            response = pipeline_response.http_response
            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))

            deserialized = _deserialize(_models.MeasurementMetadataFileInfoBase, response.json())
            if cls:
                return cls(pipeline_response, deserialized, response_headers)
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def get_writable_uri(self, measurement_id: str, **kwargs: Any) -> _models.MeasurementMetadataFileInfoBase:
        """Returns SAS signed URI that allows uploading temporary measurement metadata file to Azure
        Storage.
        This URI expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: MeasurementMetadataFileInfoBase. The MeasurementMetadataFileInfoBase is compatible
         with MutableMapping
        :rtype: ~adp.datamanagement.models.MeasurementMetadataFileInfoBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.MeasurementMetadataFileInfoBase] = kwargs.pop("cls", None)

        request = build_data_management_get_writable_uri_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))

        deserialized = _deserialize(_models.MeasurementMetadataFileInfoBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, measurement_id: str, **kwargs: Any) -> _models.MeasurementMetadataSchemaFileInfoBase:
        """Returns the measurement metadata schema file information.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: MeasurementMetadataSchemaFileInfoBase. The MeasurementMetadataSchemaFileInfoBase is
         compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.MeasurementMetadataSchemaFileInfoBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.MeasurementMetadataSchemaFileInfoBase] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.MeasurementMetadataSchemaFileInfoBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, measurement_id: str, schema_name: str, **kwargs: Any) -> _models.MeasurementClassification:
        """Get measurement classification by schema name.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param schema_name: Classification schema name. Required.
        :type schema_name: str
        :return: MeasurementClassification. The MeasurementClassification is compatible with
         MutableMapping
        :rtype: ~adp.datamanagement.models.MeasurementClassification
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.MeasurementClassification] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            schema_name=schema_name,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.MeasurementClassification, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _create_initial(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.MeasurementClassification, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.MeasurementClassification, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.MeasurementClassification, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.MeasurementClassification, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_create(
        self,
        measurement_id: str,
        body: Union[Optional[_models.MeasurementClassification], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns classification to the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'MeasurementClassificationCreationParameters' in the body.
         Default value is None.
        :type body: ~adp.datamanagement.models.MeasurementClassification or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementClassification or An instance of
         LROPoller that returns DefaultLroResponse. The MeasurementClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_create(
        self,
        measurement_id: str,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns classification to the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'MeasurementClassificationCreationParameters' in the body.
         Default value is None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementClassification or An instance of
         LROPoller that returns DefaultLroResponse. The MeasurementClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_create(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.MeasurementClassification, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.MeasurementClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns classification to the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'MeasurementClassificationCreationParameters' in the body. Is
         either a model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.MeasurementClassification or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns MeasurementClassification or An instance of
         LROPoller that returns DefaultLroResponse. The MeasurementClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.MeasurementClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.MeasurementClassification] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._create_initial(
                measurement_id=measurement_id,
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.MeasurementClassification, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _delete_initial(
        self, measurement_id: str, schema_name: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Optional[_models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Optional[_models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_delete_request(
            measurement_id=measurement_id,
            schema_name=schema_name,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202, 204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        deserialized = None
        response_headers = {}
        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)

        return deserialized

    @distributed_trace
    def begin_delete(
        self, measurement_id: str, schema_name: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> LROPoller[_models.DefaultLroResponse]:
        """Unassign the classification from the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param schema_name: Classification schema name. Required.
        :type schema_name: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DefaultLroResponse. The DefaultLroResponse is
         compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DefaultLroResponse] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._delete_initial(
                measurement_id=measurement_id,
                schema_name=schema_name,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response_headers = {}
            response = pipeline_response.http_response
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())
            if cls:
                return cls(pipeline_response, deserialized, response_headers)
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(self, measurement_id: str, **kwargs: Any) -> Iterable["_models.MeasurementClassification"]:
        """Lists the classifications assigned to the measurement.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :return: An iterator like instance of MeasurementClassification. The MeasurementClassification
         is compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.MeasurementClassification]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedMeasurementClassification] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedMeasurementClassification, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def get(self, measurement_id: str, data_stream_id: str, **kwargs: Any) -> _models.DataStream:
        """Get data-stream by identifier.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: DataStream. The DataStream is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.DataStream
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStream] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.DataStream, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _create_initial(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.DataStream, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.DataStream, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.DataStream, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            measurement_id=measurement_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DataStream, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_create(
        self,
        measurement_id: str,
        body: Union[Optional[_models.DataStream], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Creates new data-stream resource.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'DataStreamCreationParameters' in the body. Default value is
         None.
        :type body: ~adp.datamanagement.models.DataStream or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_create(
        self,
        measurement_id: str,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Creates new data-stream resource.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'DataStreamCreationParameters' in the body. Default value is
         None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_create(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.DataStream, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Creates new data-stream resource.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'DataStreamCreationParameters' in the body. Is either a model
         type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.DataStream or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.DataStream] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._create_initial(
                measurement_id=measurement_id,
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DataStream, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _clear_content_initial(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.DataStream, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.DataStream, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_clear_content_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DataStream, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_clear_content(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Clear the data-stream content.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStream] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._clear_content_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DataStream, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(
        self, measurement_id: str, *, filter: Optional[str] = None, **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the existing data-streams.
        Supports the following filter expressions:


        * filter="type=[System | Raw | Derived]".

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :keyword filter: Filter the result list using the given expression. Default value is None.
        :paramtype filter: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDataStream] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    filter=filter,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStream, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def stage_files(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[_models.UploadDerivedDataStreamFilesRequest], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.UploadDerivedDataStreamFilesResponse:
        """Returns SAS-signed upload URIs for files that need to be uploaded to Azure Storage.
        This URI expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'UploadDerivedDataStreamFilesRequest' in the body. Default value
         is None.
        :type body: ~adp.datamanagement.models.UploadDerivedDataStreamFilesRequest or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: UploadDerivedDataStreamFilesResponse. The UploadDerivedDataStreamFilesResponse is
         compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.UploadDerivedDataStreamFilesResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def stage_files(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.UploadDerivedDataStreamFilesResponse:
        """Returns SAS-signed upload URIs for files that need to be uploaded to Azure Storage.
        This URI expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'UploadDerivedDataStreamFilesRequest' in the body. Default value
         is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: UploadDerivedDataStreamFilesResponse. The UploadDerivedDataStreamFilesResponse is
         compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.UploadDerivedDataStreamFilesResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def stage_files(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[Union[_models.UploadDerivedDataStreamFilesRequest, JSON, IO]]] = None,
        **kwargs: Any
    ) -> _models.UploadDerivedDataStreamFilesResponse:
        """Returns SAS-signed upload URIs for files that need to be uploaded to Azure Storage.
        This URI expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'UploadDerivedDataStreamFilesRequest' in the body. Is either a
         model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.UploadDerivedDataStreamFilesRequest or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: UploadDerivedDataStreamFilesResponse. The UploadDerivedDataStreamFilesResponse is
         compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.UploadDerivedDataStreamFilesResponse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.UploadDerivedDataStreamFilesResponse] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_stage_files_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.UploadDerivedDataStreamFilesResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _complete_initial(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.DataStream, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.DataStream, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_complete_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DataStream, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_complete(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Marks a data stream as completed.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStream] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._complete_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DataStream, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _fail_initial(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models.DataStream, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models.DataStream, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_fail_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DataStream, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_fail(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[LROPoller[_models.DataStream], LROPoller[_models.DefaultLroResponse]]:
        """Marks a data stream as failed.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStream or An instance of LROPoller that
         returns DefaultLroResponse. The DataStream is compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStream] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStream] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._fail_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DataStream, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @overload
    def find_by_tags(
        self,
        measurement_id: str,
        body: Union[Optional[_models.FindDataStreamByTagsRequestParameters], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by tags.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByTagsRequestParameters' in the body. Default
         value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByTagsRequestParameters or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def find_by_tags(
        self, measurement_id: str, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by tags.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByTagsRequestParameters' in the body. Default
         value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def find_by_tags(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.FindDataStreamByTagsRequestParameters, JSON, IO]]] = None,
        **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by tags.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByTagsRequestParameters' in the body. Is either a
         model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByTagsRequestParameters or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models._models.PagedDataStream] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_find_by_tags_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    content_type=content_type,
                    content=_content,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStream, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def find_by_lineage(
        self,
        measurement_id: str,
        body: Union[Optional[_models.FindDataStreamByLineageRequestParameters], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by lineage.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageRequestParameters' in the body. Default
         value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByLineageRequestParameters or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def find_by_lineage(
        self, measurement_id: str, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by lineage.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageRequestParameters' in the body. Default
         value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def find_by_lineage(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.FindDataStreamByLineageRequestParameters, JSON, IO]]] = None,
        **kwargs: Any
    ) -> Iterable["_models.DataStream"]:
        """Lists the data-streams by lineage.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageRequestParameters' in the body. Is
         either a model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByLineageRequestParameters or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: An iterator like instance of DataStream. The DataStream is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStream]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models._models.PagedDataStream] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_find_by_lineage_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    content_type=content_type,
                    content=_content,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStream, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def get_lineage_graphs_by_lineage(
        self,
        measurement_id: str,
        body: Union[Optional[_models.FindDataStreamByLineageGraphRequestParameters], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Iterable["_models.DataStreamsGraphListResponse"]:
        """Lists the data-streams by lineage graph.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageGraphRequestParameters' in the body.
         Default value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByLineageGraphRequestParameters or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStreamsGraphListResponse. The
         DataStreamsGraphListResponse is compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamsGraphListResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def get_lineage_graphs_by_lineage(
        self, measurement_id: str, body: Optional[IO] = None, *, content_type: str = "application/json", **kwargs: Any
    ) -> Iterable["_models.DataStreamsGraphListResponse"]:
        """Lists the data-streams by lineage graph.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageGraphRequestParameters' in the body.
         Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An iterator like instance of DataStreamsGraphListResponse. The
         DataStreamsGraphListResponse is compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamsGraphListResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def get_lineage_graphs_by_lineage(
        self,
        measurement_id: str,
        body: Union[Optional[Union[_models.FindDataStreamByLineageGraphRequestParameters, JSON, IO]]] = None,
        **kwargs: Any
    ) -> Iterable["_models.DataStreamsGraphListResponse"]:
        """Lists the data-streams by lineage graph.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param body: Parameter of type 'FindDataStreamByLineageGraphRequestParameters' in the body. Is
         either a model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.FindDataStreamByLineageGraphRequestParameters or JSON or
         IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: An iterator like instance of DataStreamsGraphListResponse. The
         DataStreamsGraphListResponse is compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamsGraphListResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models._models.PagedDataStreamsGraphListResponse] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})
        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_get_lineage_graphs_by_lineage_request(
                    measurement_id=measurement_id,
                    api_version=self._config.api_version,
                    content_type=content_type,
                    content=_content,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStreamsGraphListResponse, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @overload
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[_models.Storage], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.StorageBase:
        """Create or replace storage information of the data-stream.
        Returns the data-stream storage resource with SAS signed URIs that allow uploading to Azure
        Storage.
        The SAS token expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'StorageCreationParameters' in the body. Default value is None.
        :type body: ~adp.datamanagement.models.Storage or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: StorageBase. The StorageBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.StorageBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.StorageBase:
        """Create or replace storage information of the data-stream.
        Returns the data-stream storage resource with SAS signed URIs that allow uploading to Azure
        Storage.
        The SAS token expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'StorageCreationParameters' in the body. Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: StorageBase. The StorageBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.StorageBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[Union[_models.Storage, JSON, IO]]] = None,
        **kwargs: Any
    ) -> _models.StorageBase:
        """Create or replace storage information of the data-stream.
        Returns the data-stream storage resource with SAS signed URIs that allow uploading to Azure
        Storage.
        The SAS token expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'StorageCreationParameters' in the body. Is either a model type
         or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.Storage or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: StorageBase. The StorageBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.StorageBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.StorageBase] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            deserialized = _deserialize(_models.StorageBase, response.json())

        if response.status_code == 201:
            deserialized = _deserialize(_models.StorageBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get_writable_uris(self, measurement_id: str, data_stream_id: str, **kwargs: Any) -> _models.StorageBase:
        """Returns the data-stream storage resource with SAS signed URIs that allow uploading to Azure
        Storage.
        The SAS token expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: StorageBase. The StorageBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.StorageBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.StorageBase] = kwargs.pop("cls", None)

        request = build_data_management_get_writable_uris_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.StorageBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(self, measurement_id: str, data_stream_id: str, **kwargs: Any) -> _models.TagSet:
        """Returns set of the data-stream tags.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: TagSet. The TagSet is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.TagSet
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.TagSet] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.TagSet, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[_models.TagSet], JSON] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.TagSetBase:
        """Create or replace all tags at once.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'TagSetCreationParameters' in the body. Default value is None.
        :type body: ~adp.datamanagement.models.TagSet or JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: TagSetBase. The TagSetBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.TagSetBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.TagSetBase:
        """Create or replace all tags at once.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'TagSetCreationParameters' in the body. Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: TagSetBase. The TagSetBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.TagSetBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[Union[_models.TagSet, JSON, IO]]] = None,
        **kwargs: Any
    ) -> _models.TagSetBase:
        """Create or replace all tags at once.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'TagSetCreationParameters' in the body. Is either a model type
         or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.TagSet or JSON or IO
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :return: TagSetBase. The TagSetBase is compatible with MutableMapping
        :rtype: ~adp.datamanagement.models.TagSetBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.TagSetBase] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.status_code == 200:
            deserialized = _deserialize(_models.TagSetBase, response.json())

        if response.status_code == 201:
            deserialized = _deserialize(_models.TagSetBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list(self, measurement_id: str, data_stream_id: str, **kwargs: Any) -> Iterable["_models.DataStreamFile"]:
        """Returns SAS signed URIs for reading special files from Azure Storage.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: An iterator like instance of DataStreamFile. The DataStreamFile is compatible with
         MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDataStreamFile] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    measurement_id=measurement_id,
                    data_stream_id=data_stream_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStreamFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _generate_initial(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> Union[_models._models.PagedDataStreamFile, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Union[_models._models.PagedDataStreamFile, _models.DefaultLroResponse]] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        request = build_data_management_generate_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models._models.PagedDataStreamFile, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def begin_generate(
        self, measurement_id: str, data_stream_id: str, *, operation_id: Optional[str] = None, **kwargs: Any
    ) -> LROPoller[Iterable["_models.DataStreamFile"]]:
        """Initiates the process of generating SAS signed URIs for accessing the data-stream files.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns an iterator like instance of PagedDataStreamFile
         or An instance of LROPoller that returns an iterator like instance of DefaultLroResponse. The
         DataStreamFile is compatible with MutableMapping
        :rtype:
         ~azure.core.polling.LROPoller[~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamFile]]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDataStreamFile] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_generate_request(
                    measurement_id=measurement_id,
                    data_stream_id=data_stream_id,
                    api_version=self._config.api_version,
                    operation_id=operation_id,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStreamFile, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._generate_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            def internal_get_next(next_link=None):
                if next_link is None:
                    return pipeline_response
                return get_next(next_link)

            return ItemPaged(internal_get_next, extract_data)

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def get_writable_uri(
        self, measurement_id: str, data_stream_id: str, **kwargs: Any
    ) -> _models.DataStreamLogsContainerBase:
        """Returns SAS signed URI of the data-stream logs folder that allow uploading log files to Azure
        Storage.
        The SAS token expires in 24 hours.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: DataStreamLogsContainerBase. The DataStreamLogsContainerBase is compatible with
         MutableMapping
        :rtype: ~adp.datamanagement.models.DataStreamLogsContainerBase
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStreamLogsContainerBase] = kwargs.pop("cls", None)

        request = build_data_management_get_writable_uri_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.DataStreamLogsContainerBase, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def get(
        self, measurement_id: str, data_stream_id: str, schema_name: str, **kwargs: Any
    ) -> _models.DataStreamClassification:
        """Get classification by schema name.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param schema_name: Classification schema name. Required.
        :type schema_name: str
        :return: DataStreamClassification. The DataStreamClassification is compatible with
         MutableMapping
        :rtype: ~adp.datamanagement.models.DataStreamClassification
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DataStreamClassification] = kwargs.pop("cls", None)

        request = build_data_management_get_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            schema_name=schema_name,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        deserialized = _deserialize(_models.DataStreamClassification, response.json())

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    def _create_initial(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[Union[_models.DataStreamClassification, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[_models.DataStreamClassification, _models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Union[_models.DataStreamClassification, _models.DefaultLroResponse]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _content = json.dumps(body, cls=AzureJSONEncoder)
            else:
                _content = None

        request = build_data_management_create_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            api_version=self._config.api_version,
            operation_id=operation_id,
            content_type=content_type,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            deserialized = _deserialize(_models.DataStreamClassification, response.json())

        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[_models.DataStreamClassification], JSON] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStreamClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns the classification to the data-stream.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'DataStreamClassificationCreationParameters' in the body.
         Default value is None.
        :type body: ~adp.datamanagement.models.DataStreamClassification or JSON
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStreamClassification or An instance of
         LROPoller that returns DefaultLroResponse. The DataStreamClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStreamClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Optional[IO] = None,
        *,
        operation_id: Optional[str] = None,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStreamClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns the classification to the data-stream.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'DataStreamClassificationCreationParameters' in the body.
         Default value is None.
        :type body: IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStreamClassification or An instance of
         LROPoller that returns DefaultLroResponse. The DataStreamClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStreamClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_create(
        self,
        measurement_id: str,
        data_stream_id: str,
        body: Union[Optional[Union[_models.DataStreamClassification, JSON, IO]]] = None,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Union[LROPoller[_models.DataStreamClassification], LROPoller[_models.DefaultLroResponse]]:
        """Assigns the classification to the data-stream.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param body: Parameter of type 'DataStreamClassificationCreationParameters' in the body. Is
         either a model type or a IO type. Default value is None.
        :type body: ~adp.datamanagement.models.DataStreamClassification or JSON or IO
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword content_type: Body parameter Content-Type. Known values are: application/json. Default
         value is None.
        :paramtype content_type: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DataStreamClassification or An instance of
         LROPoller that returns DefaultLroResponse. The DataStreamClassification is compatible with
         MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DataStreamClassification] or
         ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.DataStreamClassification] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._create_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                body=body,
                operation_id=operation_id,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response = pipeline_response.http_response
            deserialized = _deserialize(_models.DataStreamClassification, response.json())
            if cls:
                return cls(pipeline_response, deserialized, {})
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    def _delete_initial(
        self,
        measurement_id: str,
        data_stream_id: str,
        schema_name: str,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> Optional[_models.DefaultLroResponse]:
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[Optional[_models.DefaultLroResponse]] = kwargs.pop("cls", None)

        request = build_data_management_delete_request(
            measurement_id=measurement_id,
            data_stream_id=data_stream_id,
            schema_name=schema_name,
            api_version=self._config.api_version,
            operation_id=operation_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)

        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202, 204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.CustomErrorResponse, response.json())
            raise HttpResponseError(response=response, model=error)

        deserialized = None
        response_headers = {}
        if response.status_code == 202:
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)

        return deserialized

    @distributed_trace
    def begin_delete(
        self,
        measurement_id: str,
        data_stream_id: str,
        schema_name: str,
        *,
        operation_id: Optional[str] = None,
        **kwargs: Any
    ) -> LROPoller[_models.DefaultLroResponse]:
        """Unassign the classification from the data-stream.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :param schema_name: Classification schema name. Required.
        :type schema_name: str
        :keyword operation_id: The long running operation identifier. Operation-Id should be valid UUID
         string. Default value is None.
        :paramtype operation_id: str
        :keyword str continuation_token: A continuation token to restart a poller from a saved state.
        :keyword polling: By default, your polling method will be LROBasePolling. Pass in False for
         this operation to not poll, or pass in your own initialized polling object for a personal
         polling strategy.
        :paramtype polling: bool or ~azure.core.polling.PollingMethod
        :keyword int polling_interval: Default waiting time between two polls for LRO operations if no
         Retry-After header is present.
        :return: An instance of LROPoller that returns DefaultLroResponse. The DefaultLroResponse is
         compatible with MutableMapping
        :rtype: ~azure.core.polling.LROPoller[~adp.datamanagement.models.DefaultLroResponse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DefaultLroResponse] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._delete_initial(
                measurement_id=measurement_id,
                data_stream_id=data_stream_id,
                schema_name=schema_name,
                operation_id=operation_id,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            response_headers = {}
            response = pipeline_response.http_response
            response_headers["Operation-Location"] = self._deserialize(
                "str", response.headers.get("Operation-Location")
            )

            deserialized = _deserialize(_models.DefaultLroResponse, response.json())
            if cls:
                return cls(pipeline_response, deserialized, response_headers)
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller.from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller(self._client, raw_result, get_long_running_output, polling_method)  # type: ignore

    @distributed_trace
    def list(
        self, measurement_id: str, data_stream_id: str, **kwargs: Any
    ) -> Iterable["_models.DataStreamClassification"]:
        """Lists the classifications assigned to the data-stream.

        :param measurement_id: The measurement identifier. Required.
        :type measurement_id: str
        :param data_stream_id: The data stream identifier. Required.
        :type data_stream_id: str
        :return: An iterator like instance of DataStreamClassification. The DataStreamClassification is
         compatible with MutableMapping
        :rtype: ~azure.core.paging.ItemPaged[~adp.datamanagement.models.DataStreamClassification]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.PagedDataStreamClassification] = kwargs.pop(
            "cls", None
        )  # pylint: disable=protected-access

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_data_management_list_request(
                    measurement_id=measurement_id,
                    data_stream_id=data_stream_id,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)

            return request

        def extract_data(pipeline_response):
            deserialized = _deserialize(_models._models.PagedDataStreamClassification, pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)
